<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>Tingting Zheng</title>
    <style type="text/css">
        h1{
            text-align: center;
            font-size: 50px;
        }
    </style>
    <script async defer src="https://buttons.github.io/buttons.js"></script>
</head>
<body>
<!--     <h1>Seeking for a Master Degree...</h1>   -->
    <br>
</body>
</html>

<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
		<style media="screen" type="text/css">
		/* <link rel="shortcut icon" type="image/x-icon" href="./favicon.ico" media="screen" />
		body{
			border: 0pt none;
			font-family: inherit;
			font-size: 100%;
			font-style: inherit;
			font-weight: inherit;
			margin: 0pt;
			outline-color: invert;
			outline-style: none;
			outline-width: 0pt;
			padding: 0pt;
			vertical-align: baseline;
		} */
		body {
			position: relative;
			margin: 3em auto 2em auto;
			width: 1080px;
			font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
			font-size: 14px;
			background: #fdfdfd;
		}
		</style>

	<script>
		var _hmt = _hmt || [];
		(function() {
			var hm = document.createElement("script");
			hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
			var s = document.getElementsByTagName("script")[0];
			s.parentNode.insertBefore(hm, s);
		})();
	</script>
</head>
<!-- <a href="https://vilab.hit.edu.cn/index.html" target="_blank">VILab-HIT</a> -->
<body>
	<table align="center">
	<tr>
	<!-- ÁÆÄÂéÜ‰∏äÁöÑÂõæÁâá -->
	<td align="center"><img border=0 style="border-radius:8px;" height="100%" width=180 src="assets\img\zttcartoon.jpg"></td>
	<td align="center">&nbsp</td>
	<td align="center">&nbsp</td>
	<td align="center">
		<td align="center"><h2>Tingting Zheng</h2>
		     <p><font size=+1><b>ÈÉëÂÅúÂÅú</b><br><br>Ph.D. Student<br><a href="https://vilab.hit.edu.cn/index.html" target="_blank"><b>VILab-HIT@HIT</b></a></font></p>
		     <p><font size=+1>Email: <a href="mailto:zhengtingting008@gmail.com"><i>zhengtingting008@gmail.com</i></a></font><br></p>
		     <p align="center">
			    &nbsp;&nbsp;&nbsp;&nbsp;
				<!-- GitHub -->
					<a href="https://github.com/titizheng" target="_blank">
					  <img src="assets\img\github.png" alt="Github" width="60px"/>
					</a>
					&nbsp;
					<a href="https://twitter.com/zhengtingt25915" target="_blank">
						<img src="assets\img\twitter_logo.png" alt="Twitter" width="60px"/>
					  </a>
					&nbsp;
					<a href="CV\2023-5-22CV.pdf" target="_blank",label='CV'>
						<!-- <img src="img/logo/cv.png" alt="CV" width="33px"/>  -->
						<img src="assets\img\CV.png" alt="CV" width="25px"/>
					</a>

					
					
            </p>
		</td>			
	</td>		
	</tr>
	</table>
	<br>
	
	<h2>Biography</h2>
	<hr/>
	<p>
	    <font size="4">
		    I'm currently a  Ph.D. student at <a href="https://vilab.hit.edu.cn/index.html">VILab-HIT@HIT</a>, Harbin Institute of Technology, supervised by Prof. Hongxun Yao. Previously, 
			I received my M.Eng. degree from Northeastern University. I'm broadly interested in the field of computer vision. My current research focuses on image.	    
	    </font>
    </p>
	<br>

	<h2>Research Interests</h2>
	<hr/>
	<p>
		<font size="4">
			<a href="https://en.wikipedia.org/wiki/Machine_learning" target="_blank">Machine Learning</a>, 
			<a href="https://en.wikipedia.org/wiki/Computer_vision" target="_blank">Computer Vision</a>, 
			<a href="https://en.wikipedia.org/wiki/Deep_learning" target="_blank">Deep Learning</a>,
			<a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">Reinforcement Learning</a>
		</font>
	</p>
	<br>

	<h2>‚ú® News! ‚ú®</h2>
	<hr/>
	<ul>
		<li><font size="4"><b>2023.05:</b> Looking forward to good news tomorrow  !  !</li>
		
	</ul>
	<!-- <ul>
		<li><font size="4"><b>2020.03.06:</b> 1 paper was accepted by <a href="https://www.2020.ieeeicme.org/" target="_blank">ICME 2020</a> !</font></li>
		<li><font size="4"><b>2020.02.24:</b> 1 paper was accepted by <a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR 2020</a> !</font></li>
	</ul> -->
	<br>	

	
	
	
		
	<!-- <h2>Books</h2>
	<hr/>
	<table>
	<tr>   
		<td><font size="3"><b>1.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="180" src="img/publication/L0CV_profile-en.png" alt="Book: Computer Vision in Action" title="Book: Computer Vision in Action"></center></td>
		<td></td>
		<td></td>
		<td>
			<font size="4">
				<b>ËÆ°ÁÆóÊú∫ËßÜËßâÂÆûÊàòÊºîÁªÉÔºöÁÆóÊ≥ï‰∏éÂ∫îÁî®</b><br>
			</font>
			<font size="3">
				<b>Computer Vision in Action</b>
			</font>	    
			<font size="3">
				&nbsp;&nbsp; <br><br><b>Wei Zhang*</b>
				&nbsp;&nbsp; <br> <i><b>Computer Vision Algorithms and Applications</b>, a Chinese e-book contains source code, notebook, reader exchange community. </i> 
				&nbsp;&nbsp; <br><br>[<a href="https://charmve.github.io/L0CV-web" target="_blank">Project website</a>]
														| [<a href="https://charmve.github.io/computer-vision-in-action/" target="_blank"><b>üìò Online book</b></a>]
														| [<a href="https://github.com/Charmve/computer-vision-in-action" target="_blank"><img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub</a>]
														| <a href="https://charmve.github.io/computer-vision-in-action/" target="_blank"><img src="https://img.shields.io/badge/Âú®Á∫øÈòÖËØª-ÁÆÄ‰Ωì‰∏≠Êñá-000000.svg?logo=GitBook" style="vertical-align: bottom;" alt="‰∏≠ÊñáÁîµÂ≠ê‰π¶"></a>
														<a href="https://github.com/Charmve/computer-vision-in-action/edit/master/README.md"><img src="https://img.shields.io/github/stars/Charmve/computer-vision-in-action?style=social" style="vertical-align: bottom;" alt="Stars"></a>
				<a href="https://github.com/Charmve/computer-vision-in-action/edit/master/README.md"><img src="https://img.shields.io/github/forks/Charmve/computer-vision-in-action?style=social" style="vertical-align: bottom;" alt="Forks"></a>
		</font>
		</td>
	</tr>
	</table>
	<br> -->

	<!-- <h2>Research Experience</h2>
	<hr/>
	<table>

    <tr>   
		<td><font size="3"><b>5.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/surface_dataset.png" alt="Surface Defect Detection"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
                <b>   Surface Defect Detection: Paper & Dataset</b>
			</font>	    
			<font size="3">
			<br>
			<br>Constantly summarizing open source dataset and important critical papers in the field of surface defect research are very important.
			<br><br> NEU-CLS, elpv-dataset, KolektorSDD, DeepPCB, AITEX, DAGM 2007, Cracks on the surface of the construction, Magnetic Tile, RSDDs Kylberg Texture, etc.
                        <ul class="list-inline">
                            <a class="github-button"
                                href="https://github.com/Charmve/Surface-Defect-Detection"
                                data-icon="octicon-star" data-show-count="true"
                                aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
                            <a class="github-button"
                                href="https://github.com/Charmve/Surface-Defect-Detection/fork"
                                data-icon="octicon-repo-forked" data-show-count="true"
                                aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
                       </ul>
		       <br><img src="https://img.icons8.com/material-sharp/24/000000/github.png" alt="Github" width="22px"/>
			    <a href="https://github.com/Charmve/Surface-Defect-Detection" target="_blank">https://github.com/Charmve/Surface-Defect-Detection</a>
		       <br><br>
		</td>
	</tr>
-->
	<!-- <tr>   
		<td><font size="3"><b>5.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/VOGUE.png" alt="Surface Defect Detection"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
				<b>   Try-On by StyleGAN Interpolation Optimization</b>
			</font>	    
			<font size="3">
			<br>
			<br>Personal repository for "VOGUE: Try-On by StyleGAN Interpolation Optimization" (CVPR 2021), which is a StyleGAN interpolation optimization algorithm for photo-realistic try-on. SOTA results for garments to deform according to the given body shape, while preserving pattern and material details.
			<br>
			<ul class="list-inline">
					<a class="github-button"
						href="https://github.com/Charmve/VOGUE-Try-On"
						data-icon="octicon-star" data-show-count="true"
						aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
					<a class="github-button"
						href="https://github.com/Charmve/VOGUE-Try-On/fork"
						data-icon="octicon-repo-forked" data-show-count="true"
						aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
			</ul>
			<br>
			<a href="https://github.com/Charmve/VOGUE-Try-On" target="_blank">
				<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
			</a>
			 | <a href="https://charmve.github.io/VOGUE-Try-On/web_home/demo_rewrite.html" target="_blank">‚úÖ demo</a>
			 | <a href="https://charmve.github.io/VOGUE-Try-On/web_home/" target="_blank">üìÑ Homepage</a>
			<br><br>
		</td>
	</tr>
	<tr>   
		<td><font size="3"><b>4.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/stegastamp.png" alt="Surface Defect Detection"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
                <b>   StegaStamp-plus</b>
			</font>	    
			<font size="3">
			<br>
			<br> The project explores hiding data in images while maintaining perceptual similarity. Our contribution is the ability to extract the data after the encoded image (StegaStamp) has been printed and photographed with a camera (these steps introduce image corruptions).
			<br>
                        <ul class="list-inline">
                            <a class="github-button"
                                href="https://github.com/Charmve/StegaStamp-plus"
                                data-icon="octicon-star" data-show-count="true"
                                aria-label="Star Charmve/Surface-Defect-Detection on GitHub">Star</a>
                            <a class="github-button"
                                href="https://github.com/Charmve/StegaStamp-plus/fork"
                                data-icon="octicon-repo-forked" data-show-count="true"
                                aria-label="Fork Charmve/Surface-Defect-Detection on GitHub">Fork</a>
                       </ul>
		       <br>
				<a href="https://github.com/Charmve/StegaStamp-plus" target="_blank">
					<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
				</a>
				 | <a href="https://colab.research.google.com/github/Charmve/StegaStamp/blob/master/StegaStamp_train_model.ipynb" target="_blank">üìÑ Colab</a>
		         | [<a href="https://charmve.github.io/steganography.js/examples/showcase/" target="_blank"><b>steganography.js</b></a>] | [<a href="https://github.com/Charmve/PyStegosploit" target="_blank"><b>PyStegosploit</b></a>]
				<br><br>
		</td>
	</tr>
	<tr>   
		<td><font size="3"><b>3.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/glrass_detection.jpg" alt="GlassDetection"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
			    <b>  Mirror & Glass Detection in Real-world Scenes </b>
			</font>	    
			<font size="3">
		            <br>
			    <br>   I'm more interested in detecting general glass surfaces that may not possess any special properties, 
				and am developing computational models for automatic detection and segmentation of mirror and transparent glass surfaces.
			    <br>
				Thanks for <i>cs.cityu.edu.hk.</i>
			    <br>
			    <ul class="list-inline">
                                 <a class="github-button"
                                     href="https://github.com/Charmve/Mirror-Glass-Detection"
                                     data-icon="octicon-star" data-show-count="true"
                                     aria-label="Star Charmve/Mirror-Glass-Detection on GitHub">Star</a>
                                 <a class="github-button"
                                     href="https://github.com/Charmve/Mirror-Glass-Detection/fork"
                                     data-icon="octicon-repo-forked" data-show-count="true"
                                     aria-label="Fork Charmve/Mirror-Glass-Detection on GitHub">Fork</a>
                            </ul>
			    <br>
				<a href="https://github.com/Charmve/Mirror-Glass-Detection" target="_blank">
					<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
				</a>
			    <br><br>
			</font>
		</td>
	</tr>
	<tr>   
		<td><font size="3"><b>2.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/sne-roadseg.png" alt="SNE-RoadSeg2"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
			    <b>   SNE-RoadSeg2: Accurate Freespace Detection</b>
			</font>	    
			<font size="3">
			    <br>
			    <br>   PyTorch implementation of <i>SNE-RoadSeg: Incorporating Surface Normal Information into Semantic Segmentation for Accurate Freespace Detection</i> 
			    <br>
                            <ul class="list-inline">
                                <a class="github-button"
                                    href="https://github.com/Charmve/SNE-RoadSeg2"
                                    data-icon="octicon-star" data-show-count="true"
                                    aria-label="Star Charmve/SNE-RoadSeg2 on GitHub">Star</a>
                                <a class="github-button"
                                    href="https://github.com/Charmve/SNE-RoadSeg2/fork"
                                    data-icon="octicon-repo-forked" data-show-count="true"
                                    aria-label="Fork Charmve/SNE-RoadSeg2 on GitHub">Fork</a>
                            </ul>
			    <br>
				<a href="https://github.com/Charmve/SNE-RoadSeg2" target="_blank">
					<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
				</a>
				| <a href="http://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123750341.pdf" target="_blank">üìÑ Paper</a>
			    <br><br>
			</font>
		</td>
	</tr>
	<tr>   
		<td><font size="3"><b>1.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="https://img-blog.csdnimg.cn/20200706154355286.png" alt="LightCube"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
				<b>   Light Cube: A Design of 3D Dynamic Display System Based-on Voice Control</b>
			</font>	    
			<font size="3">
			<br>
			    <br>   In this paper, a 3D dynamic display system based-on voice control is presented, which solves the existing light cube display color single, low resolution, poor human-computer interaction performance, complex design, high cost, etc.
			    <br><br>
             <ul class="list-inline">
                 <a class="github-button"
                     href="https://github.com/Charmve/LightCube"
                     data-icon="octicon-star" data-show-count="true"
                     aria-label="Star Charmve/Design-of-a-3D-Dynamic-Display-System-Based-on-Voice-Control on GitHub">Star</a>
                 <a class="github-button"
                     href="https://github.com/Charmve/LightCube/fork"
                     data-icon="octicon-repo-forked" data-show-count="true"
                     aria-label="Fork Charmve/Design-of-a-3D-Dynamic-Display-System-Based-on-Voice-Control on GitHub">Fork</a>
             </ul>
			    <br>
				<a href="https://github.com/Charmve/LightCube" target="_blank">
					<img src="https://img.icons8.com/material-sharp/24/000000/github.png" style="vertical-align: bottom;" alt="Github" width="22px"/> GitHub
				</a>
				   | <a href="./doc/papers/‰∏ÄÁßçÂü∫‰∫éËØ≠Èü≥ÊéßÂà∂ÁöÑ3DÂä®ÊÄÅÊòæÁ§∫Á≥ªÁªüËÆæËÆ°.pdf" target="_blank">üìÑ Paper (Chinese)</a> 
				   | <a href="./doc/src/Âü∫‰∫éFPGAÁöÑÊô∫ËÉΩËØ≠Èü≥3DÂä®ÊÄÅÊòæÁ§∫Á≥ªÁªü¬∑Slides.pdf" target="_blank">üî≥ Slides</a> 
				   | <a href="https://charmve.github.io/doc/src/Âü∫‰∫éFPGAÁöÑÊô∫ËÉΩËØ≠Èü≥3DÂä®ÊÄÅÊòæÁ§∫Á≥ªÁªü¬∑Slides.pdf" target="_blank">üìÑ Patents</a> 
				   | <a href="https://www.bilibili.com/video/BV1cJ411C7NR" target="_blank">üé• Video</a>
				   | <a href="https://github.com/Charmve/EmotionCube" target="_blank">üöÄ EmotionCube</a>
		    	<br><br>
			</font>
		</td>
	</tr> -->
	<!--
	<tr>   
		<td><font size="3"><b>1.</b></font></td>&nbsp;&nbsp;
		<td><center><img width="260" src="img/project/bles_profile.jpg" alt="BLESec"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
			    <b>   Bluetooth-LE Security: Method, Tools and Protocol Stack</b>
			</font>	    
			<font size="3">
			<br>
			    <br>
			       The dangers of Bluetooth Low Energy(BLE) implementations: Unveiling zero day vulnerabilities and security flaws in modern Bluetooth LE stacks. BLE automatic fuzz tool. I am familiar with BLE protocol stack, BLE vulnerability mining, blocking, and relay <sup>[5~9]</sup>
			    <br>
                            <ul class="list-inline">
                                <a class="github-button"
                                    href="https://github.com/Charmve/BLE-Security-Attack-Defence"
                                    data-icon="octicon-star" data-show-count="true"
                                    aria-label="Star Charmve/BLE-Security-Attack-Defence on GitHub">Star</a>
                                <a class="github-button"
                                    href="https://github.com/Charmve/BLE-Security-Attack-Defence/fork"
                                    data-icon="octicon-repo-forked" data-show-count="true"
                                    aria-label="Fork Charmve/BLE-Security-Attack-Defence on GitHub">Fork</a>
                            </ul>
			    <br><a href="https://github.com/Charmve/BLE-Security-Attack-Defence" target="_blank">
					<img src="https://img.icons8.com/material-sharp/24/000000/github.png" alt="Github" width="22px"/> GitHub
				</a>
			    <br><br>
			</font>
		</td>
	</tr>
	-->
	<!-- </table>
	<br> -->
	

	<!-- <h2>Publications &nbsp;<a href="https://github.com/Charmve" target="_blank"><img src="img/logo/google-scholar.png" alt="Google Scholar" width="64px"/></a></h2> -->
	
	<h2>Selected Publications</h2>
	<hr/>
	<table>
		<!-- <tr>
			<td><br><font size="4"><b>2020</b></font></td>
		</tr> -->
		<tr>
			<td><font size="4">1.&nbsp</font></td>
			<td><center><img width="200" height="120" src="assets\img\publications\DenseCapsNet.png"></center></td>
			<td>
				<font size="4">
					<b>DenseCapsNet: Detection of COVID-19 X-ray Images Using a Capsule Network.</b>
				</font>
				<font size="3">
					&nbsp;&nbsp; <br> Hao Quan, Xiaosong Xu, <b>Tingting Zheng</b>, Zhi Li, Mingfang Zhao, Xiaoyu Cui
					&nbsp;&nbsp; <br>  <a href="https://www.sciencedirect.com/science/article/pii/S0010482521001931?via%3Dihub" target="_blank"><b>Computers in Biology and Medicine (2021).</b></a>
					&nbsp;&nbsp; <br><br> [<a href="assets\img\publications\DenseCapsNet.pdf" target="_blank"><b>PDF</b></a>]
																| [<a href="https://dblp.org/rec/journals/cbm/QuanXZLZC21.html?view=bibtex" target="_blank">BibTeX</a>]
																
				</font>
			</td>
		</tr>

		<tr>
			<td><font size="4">2.&nbsp</font></td>
			<td><center><img width="200" height="120" src="assets\img\publications\CD30.png"></center></td>
			<td>
				<font size="4">
					<b>Automatic CD30 scoring method for whole slide images of primary cutaneous CD30+ lymphoproliferative diseases.</b>
				</font>
				<font size="3">
					&nbsp;&nbsp; <br> <b>Tingting Zheng</b>, Song Zheng, Ke Wang, Hao Quan, Qun Bai, Shuqin Li, Ruiqun Qi, Yue Zhao, Xiaoyu Cui, Xinghua Gao
					&nbsp;&nbsp; <br>  <a href="http://dx.doi.org/10.1136/jcp-2022-208344" target="_blank"><b>Journal of Clinical Pathology (2022).</b></a>
					&nbsp;&nbsp; <br><br> [<a href="assets\img\publications\CD30.pdf" target="_blank"><b>PDF</b></a>]
					                    | [<a href="https://github.com/titizheng/MPSANet_BiomarkerScores" target="_blank"><b>GitHub</b></a>]
										| [<a href="https://scholar.googleusercontent.com/scholar.bib?q=info:xiDYm0GhlYUJ:scholar.google.com/&output=citation&scisdr=Cm3_ujynEPr_xc3KA4Q:AGlGAw8AAAAAZG7MG4RL3ltHltgX9osW3Le3P30&scisig=AGlGAw8AAAAAZG7MG1GeNNCZZt4JqAhwLvp3wI8&scisf=4&ct=citation&cd=-1&hl=en" target="_blank">BibTeX</a>]
																
				</font>
			</td>
		</tr>

		<tr>
			<td><font size="4">3.&nbsp</font></td>
			<td><center><img width="200" height="120" src="assets\img\publications\ShuqinLi.png"></center></td>
			<td>
				<font size="4">
					<b>A dynamic-static combination model based on radiomics features for prostate cancer using multiparametric MRI.</b>
				</font>
				<font size="3">
					&nbsp;&nbsp; <br> Shuqin Li, <b>Tingting Zheng</b>, Zhou Fan, Hui Qu, Jianfeng Wang, Jianbin Bi, Qingjie Lv, Gejun Zhang, Xiaoyu Cui, and Yue Zhao
					&nbsp;&nbsp; <br>  <a href="https://sci-hub.wf/10.1088/1361-6560/aca954" target="_blank"><b>Physics in Medicine & Biology (2022).</b></a>
					&nbsp;&nbsp; <br><br> [<a href="assets\img\publications\Li_2023_Phys._Med._Biol._68_015008.pdf" target="_blank"><b>PDF</b></a>]
																| [<a href="https://iopscience.iop.org/export?type=article&doi=10.1088/1361-6560/aca954&exportFormat=iopexport_bib&exportType=abs&navsubmit=Export+abstract" target="_blank">BibTeX</a>]
																
				</font>
			</td>
		</tr>

		<!-- <tr>
			<td><font size="4">4.&nbsp</font></td>
			<td><center><img width="200" height="120" src="assets\img\publications\DenseCapsNet.png"></center></td>
			<td>
				<font size="4">
					<b>Learning How to Detect: A Deep Reinforcement Learning Method for Whole-Slide Melanoma Histopathology Images.</b>
				</font>
				<font size="3">
					&nbsp;&nbsp; <br> Hao Quan, Xiaosong Xu, <b>Tingting Zheng</b>, Zhi Li, Mingfang Zhao, Xiaoyu Cui
					&nbsp;&nbsp; <br>  <a href="https://www.sciencedirect.com/science/article/pii/S0010482521001931?via%3Dihub" target="_blank"><b>Computers in Biology and Medicine. 133(104399) 2021.</b></a>
					&nbsp;&nbsp; <br><br> [<a href="assets\img\publications\DenseCapsNet.pdf" target="_blank"><b>PDF</b></a>]
																| [<a href="https://dblp.org/rec/journals/cbm/QuanXZLZC21.html?view=bibtex" target="_blank">BibTeX</a>]
																
				</font>
			</td>
		</tr> -->
	</table>
	

	<h2>Patents</h2>
	<hr/>
	<table>
	<tr>   
		<td><font size="3"><b>1. </b></font></td>
		<td><center><img width="260" src="Patants\RLimage.png" alt="Data Playback Tool"></center></td>
		<td></td><td></td>
		<td>
			<font size="4">
				<b>‰∏ÄÁßçÂü∫‰∫éÂº∫ÂåñÂ≠¶‰π†ÁöÑÁóÖÁêÜÂàáÁâáÊâ´ÊèèÂàÜÊûê‰∏Ä‰ΩìÂåñÊñπÊ≥ïÂèäÁ≥ªÁªü</b>
				<br>A reinforcement learning-based integrated method and system for scanning and analyzing pathological sections [P]
			</font>
			<font size="3">
                            &nbsp;&nbsp; <br>Xiaoyu Cui, Xinghua Gao, Yue Zhao, Song Zheng, Ruiqun Qi, <b>Tingting Zheng</b>, et al.
							<br> CN115564997A, 2022-09-29      [<a href="https://pss-system.cponline.cnipa.gov.cn/download/literature/2023-05-24/%E6%89%93%E5%8D%B0_7c45a3beb1f14179894c779a2ffc5f1a.pdf" target="_blank"><b>PDF</b></a>]
			    &nbsp;&nbsp; <br> 
			    <!-- &nbsp;&nbsp; <br>[<a href="" target="_blank"><b>PDF</b></a>] | [<a href="" target="_blank"><b>GitHub</b></a>] -->
			</font>
		</td>
	</tr>
	
	</table>
	<br>
		
	<!-- <h2>Software Copyrights</h2>
	<hr/>
	<table>
	<tr>	
		<td><font size="3"><b>9.</b> &nbsp Industrial Control System Network Attack Chain Automatic Generation Platform (360 Â∑•ÊéßÁΩëÁªúÊîªÂáªÈìæË∑ØËá™Âä®ÁîüÊàêÂπ≥Âè∞)[CP]. &nbsp; Bo Ye, <b>Wei Zhang</b>, Jianqiang Qu. &nbsp 2021SR1816116.</font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>8.</b> &nbsp Industrial Control System Network Topology Drawing Platform (360 Â∑•ÊéßÁΩëÁªúÊãìÊâëÁªòÂà∂Âπ≥Âè∞)[CP]. &nbsp; Bo Ye, <b>Wei Zhang</b>. &nbsp 2021SR1816115.</font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>7.</b> &nbsp An Interactive AI System Software Featuring Dynamic Facial Expression Recognition and Voice Chatting [CP]. &nbsp; <b>Wei Zhang</b>, Xiaoying Deng, Wanting Liu. &nbsp 2019R11S0455591.</font></td>
	</tr>
	<tr>	 
		<td><font size="3"><b>6.</b> &nbsp A System Software Used in a Bluetooth-controlled Car for Authentication Based on Dynamic Facial Recognition [CP]. &nbsp; <b>Wei Zhang</b>, Fuzhou Shen, Xiaoying Deng, Lei CHEN. &nbsp 2019R11S0455589.</font></td>
	</tr>
	<tr>
		<td><font size="3"><b>5.</b> &nbsp An Eco-regulation System Based on Internet and Real-time Monitoring [CP]. &nbsp; Saibo Fan, Jiqiao Sun, Fuzhou Shen, <b>Wei Zhang</b>, Lei Chen. &nbsp 2019SR0619769.</font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>4.</b> &nbsp A Smart Car System with Tracing and Photography Functions [CP]. &nbsp; Fuzhou Shen, <b>Wei Zhang</b>, Saibo Fan, Lei Chen. &nbsp 2019SR0676736.</font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>3.</b> &nbsp A 3D Dynamic Display System Based on Intelligent Voice [CP]. &nbsp; <b>Wei Zhang</b>, Fuzhou Shen, Ce Sun, Xiaoying Deng, Lei Chen. &nbsp 2019SR0223080.</font></td> 
	</tr>
	<tr>	
		<td><font size="3"><b>2.</b> &nbsp A Robot Control System Server Based on WebServer Technology [CP]. &nbsp; <b>Wei Zhang</b>, Xiaofeng Yang, Xiaoying Deng. &nbsp 2018SR879516.</font></td>
	</tr>
	<tr>	
		<td><font size="3"><b>1.</b> &nbsp An Intelligent Rainbow Light System Software Based on Wi-Fi Module [CP]. &nbsp; Shaowei Qian, Xuelian Ge, <b>Wei Zhang</b>, Xiaoming Yan, Lei Chen. &nbsp 2018SR773134.</font></td>	
	</tr>
	</table>
	<br> -->
	
	<!-- <h2>Funding</h2>
	<hr/>
	<table>
	<tr>	
		<td><br><b>1.</b>&nbsp; <font size="4">Provincial College Students‚Äô Innovative Entrepreneurial Training Program, 2019.5‚Äì2020.5</font></td>
	</tr>
	<tr>
		<td>
			<p> &nbsp;&nbsp; <font size="3">- Maiwei Information Technology Co., Ltd., <i>No. 201911117138T</i>, <b>Principal Investigator</b></font></p>
		</td>
	</tr>
	<tr>	
		<td><b>2.</b> &nbsp; <font size="4">School-level College Students' Innovative Entrepreneurial Training, 2018.5‚Äì2019.5</font> </td>
	</tr>
	<tr>
		 <td>
			<p>&nbsp;&nbsp; <font size="3">- A Design of Indoor Self-navigating Meal Delivery Robot Based on Facial Recognition, <i>No. x20180186</i>, <b>Principal Investigator</b> </font><br>
			<div style="line-height:10px"></div>&nbsp;&nbsp; <font size="3">- E-reading Aids for Visually Impaired People Based on Optical Character Recognition(OCR) and Text to Speech(TTS) Techniques, <i>No. x20180186</i>, Participator</font></p>
            
		 </td>
	</tr>
	</table>
	<br> -->

	<div id="education" class="section">
		<h2>Education Background</h2>
		<hr>
		<table cellspacing="25">
		<tr>

			<td><center><img width="100" height="80" src="assets\img\HITlogo.jpg" style="box-shadow: 3px 3px 6px #999" alt="HIT Logo"></center></td>
			<td>
				<font size="4">
					<strong>Ph.D.</strong><br>
					Sep 2023 - Present | School of Computer Science and Engineering<br>
					<a href="https://vilab.hit.edu.cn/index.html" target="_blank">VILab-HIT</a>, <a href="http://en.hit.edu.cn/" target="_blank">Harbin Institute of Technology</a>, China<br>
					Advisor: Prof. <a href="https://scholar.google.com.hk/citations?user=aOMFNFsAAAAJ" target="_blank">Hongxun Yao</a>
				</font>		
			</td>	
		</tr>

		<tr>
			<td><center><img width="100" height="80" src="assets\img\Neulogo.jpg" style="box-shadow: 3px 3px 6px #999" alt="HIT Logo"></center></td>
			<td>
				<font size="4">
					<strong>M.Eng.</strong><br>
					Sep 2023 - Jul 2022 | Electronic Information<br>
					<a href="http://english.neu.edu.cn/" target="_blank">Northeastern University</a>, China<br>
					Advisor: Prof. <a href="http://faculty.neu.edu.cn/cuixy/zh_CN/" target="_blank">Xiaoyu Cui</a> 
				</font>	
			</td>
		</tr>

		<tr>
			<td><center><img width="100" height="80" src="assets\img\HNlogo.jpg" style="box-shadow: 3px 3px 6px #999" alt="HIT Logo"></center></td>
			<td>
				<font size="4">
					<strong>B.Eng.</strong><br>
					Sep 2020 - Jul 2016 | Software Engineering<br>
					<a href="https://en.wikipedia.org/wiki/Henan_University_of_Economics_and_Law" target="_blank">Henan University of Economics and Law</a>, China<br>
				</font>
			</td>
		</tr>
		</table>
	<h2>Awards & Honors</h2>
	<hr/>
	<table>
	<tr>
		<td>
		<p>
			<font size="4"><span class="label">&#10148;</span> 06/2023 - </font><font size="3">2023 Excellent Graduated Students of Liaoning Province. </font>
			<br><font size="4"><span class="label">&#10148;</span> 06/2023 - </font><font size="3"> 2023 Excellent Graduated Students at Northeastern University. </font>
			<br><font size="4"><span class="label">&#10148;</span> 10/2022 - </font><font size="3"> 2022 Excellent Graduate Students at Northeastern University. </font>
			<br><font size="4"><span class="label">&#10148;</span> 09/2022 - </font><font size="3"> 2022 The Seventh National Student Biomedical Engineering Innovation Design Competition Third Prize. </font>
			<br><font size="4"><span class="label">&#10148;</span> 10/2021 - </font><font size="3"> 2021 Excellent Graduate Students at Northeastern University. </font>
			<br><font size="4"><span class="label">&#10148;</span> 08/2021 - </font><font size="3"> 2021 The Sixth National Student Biomedical Engineering Innovation Design Competition Second Prize. </font>
			<br><font size="4"><span class="label">&#10148;</span> 06/2020 - </font><font size="3"> 2023 Huang Tingfang/Xinhe Scholarship of Henan University of Economics and Law. </font>
			<br><font size="4"><span class="label">&#10148;</span> 11/2018 - </font><font size="3"> 2018 National Encouragement scholarship. </font>
            
            <!-- <br><font size="4"><span class="label">&#10148;</span> 08/2019 - </font><font size="3"><strong>1st Prize</strong>, The 5th China College Students' 'Internet Plus' Innovation and Entreprenurship Competition. <a href="https://www.youtube.com/watch?v=Xc_AfRVF1nw" target="_blank"><i>Maiwei Information Technology Co., Ltd.</i> </a><b>Wei ZHANG</b>, Hongxia Yu, Zhichao Fan, Shumin Li. <i>No. 201911117138T</i>, <b>Principal Investigator</b>.</font> -->
		</p>
		</td>
	</tr>
	</table>

	<!-- <h2>Social Activities</h2>
	<hr/> 
	<table>
	<tr>
		<td><font size="4"><span class="label">&#10148;</span> 08/2020-now  <b>Technical Blog Analyst</b>, Global Affairs, Synced Technology </font></td>
	</tr>
	<tr>
		<td><font size="4"><span class="label">&#10148;</span> 07/2020-now  <b>Vice-advisor</b>, Ant Academic Study Center </font></td>
	</tr>
	<tr>
		<td><font size="4"><span class="label">&#10148;</span> Volunteer Experiences (<b>OVER 250</b> hours of volunteer services)</font></td>
	</tr>
	<tr>
		<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="3.5"> 02/2020 - </font> Excellent work in respect of the volunteer program of <a href="https://unfccc.int/news/youth-urge-climate-action-at-cop25" target="_blank"><b>COP25 - Youth4Climate</b></a> to United Nations Framework Convention on Climate Change, <b>Assistant</b> to the Greater China Secretariat, <b>Excellent Group</b> </font></td>
	</tr>
	<tr>	
		<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="3.5"> 04/2019 - </font> Yangzhou Jianzhen International Half Marathon, <b>Outstanding Volunteer</b> </font></td>
	</tr>
	<tr>	
		<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="3.5"> 03/2019 - </font> Responsible for the recruitment of volunteers in mainland China for The 2019 World Summer Special Olympic Games, <b>Group Leader</b> </font></td>
	</tr>
	<tr>	
		<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="3.5"> 08/2018 - </font> Volunteering for The 19th Sports Games of Jiangsu, as an assistant referees of the youth team of basketball games </font></td>
	</tr>
	<tr>	
		<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<font size="3.5"> 07/2018 - </font> International Volunter Job in <a href="https://aiesec.org" target="_blank"><b>AIESEC</b></a> in NJU, Mainland of China's Incoming Global Volunteer program <i>Explore China7.0</i> </font></td>
	</tr>
	</table>
	<br> -->


	<h2>Website visit statistics</h2>
	<hr/>
	<!-- <div height=400 width=300 id="clustrmaps" align="center"
	
	</div> -->
	<script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=9eMptezw-NnpqYKLs5epIBAUz9ZxeCgMEnPPtd9kv0Q&cl=ffffff&w=300&h=200"></script>
	<!-- <script type="text/javascript" id="clustrmaps" src="//clustrmaps.com/map_v2.js?d=9eMptezw-NnpqYKLs5epIBAUz9ZxeCgMEnPPtd9kv0Q&cl=ffffff&w=a"></script> -->
	<!-- <a href="https://clustrmaps.com/site/1but9"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=9eMptezw-NnpqYKLs5epIBAUz9ZxeCgMEnPPtd9kv0Q&cl=ffffff" /></a> -->
    <div id="copyright" align="center">
        <p>Copyright&copy; 2023  Tingting Zheng.</p>
    </div>
</body>
</html>
